{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the DIRNDL data set\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some basic operations to analyze the portion of the DIRNDL corpus that is used to create PromDetect. The results of the operations can also be found in section [X] of the thesis. While the operations are not completely reproducible because the data is not made public, this document is supposed to still provide some insight into how the numbers in that section came to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promdetect.prep import prepare_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paths of all recording files and extract the IDs from their filenames\n",
    "corpusDir = \"/home/lukas/Dokumente/Uni/ma_thesis/quelldaten/DIRNDL-prosody\"\n",
    "recordingPaths = glob(pathname = corpusDir + \"/*.wav\")\n",
    "recordingIds = [re.split(r\".*/dlf-nachrichten-(.*)\\.wav\", rPath)[1] for rPath in recordingPaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the primary data preparation function on the annotations for all recordings and store the relevant parts in separate dictionaries\n",
    "accents = pd.DataFrame(columns = [\"time\", \"label\", \"recording\"])\n",
    "tones = pd.DataFrame(columns = [\"time\", \"label\", \"recording\"])\n",
    "transcript = pd.DataFrame(columns = [\"start\", \"end\", \"label\", \"recording\"])\n",
    "\n",
    "for recording in recordingIds:\n",
    "    currentData = prepare_data.DataPreparation(corpusDir, recording)\n",
    "    currentData.transform_annotations()\n",
    "\n",
    "    currentAccents = pd.DataFrame(currentData.accents[[\"time\", \"label\"]])\n",
    "    currentAccents[\"recording\"] = recording\n",
    "    accents = accents.append(currentAccents)\n",
    "    \n",
    "    currentTones = pd.DataFrame(currentData.tones[[\"time\", \"label\"]])\n",
    "    currentTones[\"recording\"] = recording\n",
    "    tones = tones.append(currentTones)\n",
    "    \n",
    "    currentTranscript = pd.DataFrame(currentData.transcript[[\"start\", \"end\", \"label\"]])\n",
    "    currentTranscript[\"recording\"] = recording\n",
    "    transcript = transcript.append(currentTranscript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Amount of accent boundary labels: 19631\n"
    }
   ],
   "source": [
    "accents = accents.loc[~accents[\"label\"].isna()] # drop NA-labelled rows\n",
    "print(\"Amount of accent boundary labels: {}\".format(len(accents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "L*H      7819\nH*L      6120\n!H*L     2126\nH*       2055\n..L       634\nL*        461\n!H*       263\nL*HL       53\n..H        25\nH*L?       18\n*?         17\nL*H?       13\nH*?         6\nHH*L        6\n!H*L?       3\nL*?         2\nLH*L        2\n.L          2\n!H          1\nH!          1\nL*!H        1\nH*l         1\nL*HL?       1\nH*M?        1\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "# Show frequency counts for each label\n",
    "accents[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Amount of tone boundary labels: 9216\n"
    }
   ],
   "source": [
    "tones = tones.loc[~tones[\"label\"].isna()] # drop NA-labelled rows\n",
    "print(\"Amount of tone boundary labels: {}\".format(len(tones)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-      4823\n%      4027\nH%      173\nL%      145\n%H       40\n-?        7\nH?%       1\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "# Show frequency counts for each label\n",
    "tones[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop breathing sounds, paragraph markers and empty labels\n",
    "transcript = transcript.loc[~transcript[\"label\"].isin([\"[@]\", \"[t]\", \"[n]\", \"[f]\", \"[h]\", \"<P>\", np.nan])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duration of each word by using its end and start timestamps\n",
    "transcript[\"dur\"] = transcript[\"end\"] - transcript[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get amount of word annotations\n",
    "len(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Longest transcripts:\n200703251200    1071\n200703262000     995\n200703270600     987\nName: recording, dtype: int64\n\nShortest transcripts:\n200703251100    472\n200703271100    461\n200703271500    457\nName: recording, dtype: int64\n\nMedian length: 536.0\nMean length: 642.6727272727272\n"
    }
   ],
   "source": [
    "# Get miscellaneous statistics about transcripts\n",
    "print(\"Longest transcripts:\\n{}\\n\".format(transcript[\"recording\"].value_counts().head(3)))\n",
    "print(\"Shortest transcripts:\\n{}\\n\".format(transcript[\"recording\"].value_counts().tail(3)))\n",
    "print(\"Median length: {}\".format(np.median(transcript[\"recording\"].value_counts())))\n",
    "print(\"Mean length: {}\".format(np.mean(transcript[\"recording\"].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('promdetect': venv)",
   "language": "python",
   "name": "python37364bitpromdetectvenvf0d8aec3b1634575ba564862f6a926be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}