{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the DIRNDL data set\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains some basic operations to analyze the portion of the DIRNDL corpus that is used to create PromDetect. The results of the operations can also be found in section [X] of the thesis. While the operations are not completely reproducible because the data is not made public, this document is supposed to still provide some insight into how the numbers in that section came to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promdetect.prep import prepare_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from functools import reduce\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir = \"/home/lukas/Dokumente/Uni/ma_thesis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paths of all recording files and extract the IDs from their filenames\n",
    "corpusDir = rootDir + \"quelldaten/DIRNDL-prosody\"\n",
    "recordingPaths = glob(pathname = corpusDir + \"/*.wav\")\n",
    "recordingIds = [re.split(r\".*/dlf-nachrichten-(.*)\\.wav\", rPath)[1] for rPath in recordingPaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the primary data preparation function on the annotations for all recordings and store the relevant parts in separate dictionaries\n",
    "accents = pd.DataFrame(columns = [\"time\", \"label\", \"recording\"])\n",
    "tones = pd.DataFrame(columns = [\"time\", \"label\", \"recording\"])\n",
    "transcript = pd.DataFrame(columns = [\"start\", \"end\", \"label\", \"recording\"])\n",
    "\n",
    "for recording in recordingIds:\n",
    "    currentData = prepare_data.DataPreparation(corpusDir, recording)\n",
    "    currentData.transform_annotations()\n",
    "\n",
    "    currentAccents = pd.DataFrame(currentData.accents[[\"time\", \"label\"]])\n",
    "    currentAccents[\"recording\"] = recording\n",
    "    accents = accents.append(currentAccents)\n",
    "    \n",
    "    currentTones = pd.DataFrame(currentData.tones[[\"time\", \"label\"]])\n",
    "    currentTones[\"recording\"] = recording\n",
    "    tones = tones.append(currentTones)\n",
    "    \n",
    "    currentTranscript = pd.DataFrame(currentData.transcript[[\"start\", \"end\", \"label\"]])\n",
    "    currentTranscript[\"recording\"] = recording\n",
    "    transcript = transcript.append(currentTranscript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Amount of accent boundary labels: 19631\n"
    }
   ],
   "source": [
    "accents = accents.loc[~accents[\"label\"].isna()] # drop NA-labelled rows\n",
    "print(\"Amount of accent boundary labels: {}\".format(len(accents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "L*H      7819\nH*L      6120\n!H*L     2126\nH*       2055\n..L       634\nL*        461\n!H*       263\nL*HL       53\n..H        25\nH*L?       18\n*?         17\nL*H?       13\nHH*L        6\nH*?         6\n!H*L?       3\n.L          2\nLH*L        2\nL*?         2\nH!          1\nL*!H        1\nL*HL?       1\nH*l         1\nH*M?        1\n!H          1\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Show frequency counts for each label\n",
    "accents[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze tones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Amount of tone boundary labels: 9216\n"
    }
   ],
   "source": [
    "tones = tones.loc[~tones[\"label\"].isna()] # drop NA-labelled rows\n",
    "print(\"Amount of tone boundary labels: {}\".format(len(tones)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-      4823\n%      4027\nH%      173\nL%      145\n%H       40\n-?        7\nH?%       1\nName: label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Show frequency counts for each label\n",
    "tones[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop breathing sounds, paragraph markers and empty labels\n",
    "transcript = transcript.loc[~transcript[\"label\"].isin([\"[@]\", \"[t]\", \"[n]\", \"[f]\", \"[h]\", \"<P>\", np.nan])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duration of each word by using its end and start timestamps\n",
    "transcript[\"dur\"] = transcript[\"end\"] - transcript[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Amount of word annotation labels: 35347\n"
    }
   ],
   "source": [
    "# Get amount of word annotations\n",
    "print(\"Amount of word annotation labels: {}\".format(len(transcript)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Longest transcripts:\n200703251200    1071\n200703262000     995\n200703270600     987\nName: recording, dtype: int64\n\nShortest transcripts:\n200703251100    472\n200703271100    461\n200703271500    457\nName: recording, dtype: int64\n\nMedian length: 536.0\nMean length: 642.6727272727272\n"
    }
   ],
   "source": [
    "# Get miscellaneous statistics about transcripts\n",
    "print(\"Longest transcripts:\\n{}\\n\".format(transcript[\"recording\"].value_counts().head(3)))\n",
    "print(\"Shortest transcripts:\\n{}\\n\".format(transcript[\"recording\"].value_counts().tail(3)))\n",
    "print(\"Median length: {}\".format(np.median(transcript[\"recording\"].value_counts())))\n",
    "print(\"Mean length: {}\".format(np.mean(transcript[\"recording\"].value_counts())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Analyze nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleiFiles = glob(rootDir + \"promdetect/data/dirndl/nuclei/*\")\n",
    "nucleiData = pd.DataFrame(columns = [\"start\", \"end\", \"timestamp_auto\", \"phone_label\", \"word_label\", \"origin_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nucleiFile in nucleiFiles:\n",
    "    currentData = pd.read_csv(nucleiFile, delimiter = \",\")\n",
    "    currentData[\"origin_file\"] = re.search(r\"[ \\w-]+?(?=\\.)\", nucleiFile)[0] + \".nuclei\"\n",
    "    nucleiData = nucleiData.append(currentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Most nuclei per recording:\ndlf-nachrichten-200703251200.nuclei    2084\ndlf-nachrichten-200703270600.nuclei    2024\ndlf-nachrichten-200703260600.nuclei    1957\nName: origin_file, dtype: int64\n\nLeast nuclei per recording:\ndlf-nachrichten-200703260900.nuclei    898\ndlf-nachrichten-200703271500.nuclei    884\ndlf-nachrichten-200703261900.nuclei    879\nName: origin_file, dtype: int64\n\nMedian nuclei per transcript: 1032.0\nMean nuclei per transcript: 1238.8363636363636\n"
    }
   ],
   "source": [
    "# Get miscellaneous statistics about nuclei\n",
    "print(\"Most nuclei per recording:\\n{}\\n\".format(nucleiData[\"origin_file\"].value_counts().head(3)))\n",
    "print(\"Least nuclei per recording:\\n{}\\n\".format(nucleiData[\"origin_file\"].value_counts().tail(3)))\n",
    "print(\"Median nuclei per transcript: {}\".format(np.median(nucleiData[\"origin_file\"].value_counts())))\n",
    "print(\"Mean nuclei per transcript: {}\".format(np.mean(nucleiData[\"origin_file\"].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nuclei distances\n",
    "nucleiDataGrouped = nucleiData.groupby([\"origin_file\"])\n",
    "\n",
    "nucleiData[\"timestamp_auto_next\"] = nucleiDataGrouped[\"timestamp_auto\"].shift(-1)\n",
    "\n",
    "nucleiData[\"to_next_nucleus\"] = nucleiData[\"timestamp_auto_next\"] - nucleiData[\"timestamp_auto\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Maximum space between nuclei: 31736.50 milliseconds\nMinimum space between nuclei: 41.60 milliseconds\nMedian space between nuclei: 194.38 milliseconds\nMean space between nuclei: 257.26 milliseconds\n"
    }
   ],
   "source": [
    "print(\"Maximum space between nuclei: {0:.2f} milliseconds\".format(max(nucleiData[\"to_next_nucleus\"] * 1000)))\n",
    "print(\"Minimum space between nuclei: {0:.2f} milliseconds\".format(min(nucleiData[\"to_next_nucleus\"] * 1000)))\n",
    "print(\"Median space between nuclei: {0:.2f} milliseconds\".format(np.nanmedian(nucleiData[\"to_next_nucleus\"] * 1000)))\n",
    "print(\"Mean space between nuclei: {0:.2f} milliseconds\".format(np.mean(nucleiData[\"to_next_nucleus\"] * 1000)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get speech rate indicators\n",
    "endTimes = nucleiDataGrouped[\"end\"].max().to_frame().reset_index()\n",
    "startTimes = nucleiDataGrouped[\"start\"].min().to_frame().reset_index()\n",
    "nucleusCounts = nucleiData[\"origin_file\"].value_counts().to_frame().reset_index().rename(columns = {\"index\": \"origin_file\", \"origin_file\": \"counts\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesCounts = reduce(lambda  left,right: pd.merge(left,right,on=['origin_file'],\n",
    "                                            how='outer'), [endTimes, startTimes, nucleusCounts])\n",
    "timesCounts[\"duration\"] = timesCounts[\"end\"] - timesCounts[\"start\"]\n",
    "timesCounts[\"nuc_per_min\"] = timesCounts[\"counts\"] / (timesCounts[\"duration\"] / 60)\n",
    "timesCounts[\"nuc_per_sec\"] = timesCounts[\"counts\"] / timesCounts[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Maximum nuclei per second: 4.25\nMinimum nuclei per second: 3.50\nMedian nuclei per second: 3.94\nMean nuclei per second: 3.92\n"
    }
   ],
   "source": [
    "print(\"Maximum nuclei per second: {0:.2f}\".format(max(timesCounts[\"nuc_per_sec\"])))\n",
    "print(\"Minimum nuclei per second: {0:.2f}\".format(min(timesCounts[\"nuc_per_sec\"])))\n",
    "print(\"Median nuclei per second: {0:.2f}\".format(np.nanmedian(timesCounts[\"nuc_per_sec\"])))\n",
    "print(\"Mean nuclei per second: {0:.2f}\".format(np.mean(timesCounts[\"nuc_per_sec\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('promdetect': venv)",
   "language": "python",
   "name": "python37364bitpromdetectvenvf0d8aec3b1634575ba564862f6a926be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}