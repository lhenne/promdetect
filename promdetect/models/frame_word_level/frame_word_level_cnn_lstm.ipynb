{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "frame_word_level_cnn_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bDR66Ej583MP",
        "1zPDCHL383MZ",
        "FmsHeQvW83NW",
        "Y7D02tEew9Bc",
        "mP9ZD1G5T2Zp",
        "bojp-FLoT_K4"
      ]
    },
    "environment": {
      "name": "pytorch-gpu.1-4.m49",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": "2000"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "359.933px",
        "left": "1653.71px",
        "right": "20px",
        "top": "148.966px",
        "width": "453.267px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv_maCh583MH"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H650bleQ83MJ"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDR66Ej583MP"
      },
      "source": [
        "## Set working directory and load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqQJpypKmQuD",
        "outputId": "814ee6d0-df7c-42f2-f475-d566aab9067d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4RhnIl783MQ"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OtK1rBi83MV"
      },
      "source": [
        "data_features = np.load(\"data/frame_level/frame_features.npy\", allow_pickle=True)\n",
        "data_labels = np.load(\"data/frame_level/frame_labels.npy\", allow_pickle=True)\n",
        "data_times = np.load(\"data/frame_level/frame_times.npy\", allow_pickle=True)\n",
        "\n",
        "data_words = np.load(\"data/word_level/word_features.npy\", allow_pickle=True)\n",
        "data_words_labels = np.load(\"data/word_level/word_labels.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zPDCHL383MZ"
      },
      "source": [
        "## Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DBpcnqAVZ6X"
      },
      "source": [
        "train_features, val_features, train_labels, val_labels, train_times, val_times, train_words, val_words, train_words_labels, val_words_labels  = train_test_split(data_features, data_labels, data_times, data_words, data_words_labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz0HAhRrXuvI"
      },
      "source": [
        "## Define custom Dataset class for use in the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txTaSoEjX1sc"
      },
      "source": [
        "class DatasetWithTimings(Dataset):\n",
        "  def __init__(self, features, labels, times, words, words_labels, half_times, transform=None):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.times = times\n",
        "    self.words = words\n",
        "    self.words_labels = words_labels\n",
        "    self.half_times = half_times\n",
        "    self.transform = transform\n",
        "\n",
        "    # Convert feature inputs to tensors, pad with zeroes to make them rectangular \n",
        "    self.features_input = pad_sequence(self.to_tensor_float(self.features), batch_first=True).permute(0, 2, 1)\n",
        "\n",
        "    # Reduce label sizes to the size that can be expected at system output, perform conversion & padding as above\n",
        "    self.labels_input = pad_sequence(self.to_tensor_float(self.labels), batch_first=True)\n",
        "    for i in range(self.half_times):\n",
        "      self.labels_input = np.apply_along_axis(self.delete_every_2nd, 1, self.labels_input)\n",
        "    self.labels_input = torch.cuda.FloatTensor(np.expand_dims(self.labels_input, 2))\n",
        "\n",
        "    # Convert & pad timetables to conform with other input and to make them rectangular\n",
        "    self.times_input = pad_sequence(self.to_tensor_float(self.times), batch_first=True) // 8\n",
        "\n",
        "    # Convert & pad word features & labels to conform with other input at to make them rectangular\n",
        "    self.words_input = pad_sequence(self.to_tensor_float(self.words), batch_first=True)\n",
        "\n",
        "    self.words_labels_input = pad_sequence(self.to_tensor_float(self.words_labels), batch_first=True)\n",
        "    self.words_labels_input = torch.cuda.FloatTensor(np.expand_dims(self.words_labels_input, 2))\n",
        "\n",
        "    # Check if shapes are correctly aligned (dimension 0 should be of equal size)\n",
        "    print(f\"Labels input shape: {self.labels_input.shape}\")\n",
        "    print(f\"Features input shape: {self.features_input.shape}\")\n",
        "    print(f\"Timestamps input shape: {self.times_input.shape}\")\n",
        "    print(f\"Word features input shape: {self.words_input.shape}\")\n",
        "    print(f\"Word labels input shape: {self.words_labels_input.shape}\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels_input)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    \n",
        "    features = self.features_input[idx]\n",
        "    labels = self.labels_input[idx]\n",
        "    times = self.times_input[idx]\n",
        "    words = self.words_input[idx]\n",
        "    words_labels = self.words_labels_input[idx]\n",
        "\n",
        "    sample = {\n",
        "        \"features\": features,\n",
        "        \"labels\": labels,\n",
        "        \"times\": times,\n",
        "        \"words\": words,\n",
        "        \"words_labels\": words_labels,\n",
        "        \"indices\": idx\n",
        "    }\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def to_tensor_float(self, data_list):\n",
        "    return [torch.FloatTensor(data.astype(\"float64\")) for data in data_list]\n",
        "  \n",
        "  def delete_every_2nd(self, arr):\n",
        "    return np.delete(arr, np.arange(0, arr.size-1, 2))\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_61CR4hn34O",
        "outputId": "7eb73b97-f603-4e63-9400-03fbc3a6cdb9"
      },
      "source": [
        "train_data = DatasetWithTimings(train_features, train_labels, train_times, train_words, train_words_labels, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels input shape: torch.Size([3492, 192, 1])\n",
            "Features input shape: torch.Size([3492, 7, 1529])\n",
            "Timestamps input shape: torch.Size([3492, 40, 2])\n",
            "Word features input shape: torch.Size([3492, 40, 23])\n",
            "Word labels input shape: torch.Size([3492, 40, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmsHeQvW83NW"
      },
      "source": [
        "## Define ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTZq-OAVjCcE"
      },
      "source": [
        "SENTS = train_data.features_input.shape[0]\n",
        "FEATURES = train_data.features_input.shape[1]\n",
        "POINTS = train_data.features_input.shape[2]\n",
        "PADDED_WORDS_MAX = train_data.times_input.shape[1]\n",
        "KERNEL_SIZE = 11\n",
        "BATCH_SIZE = 499\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 30\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mitWyvzrGTw"
      },
      "source": [
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJEVOvB-83NW"
      },
      "source": [
        "class binaryClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        super(binaryClassifier, self).__init__()\n",
        "\n",
        "        self.cnn_1 = nn.Conv1d(in_channels=FEATURES, out_channels=128, kernel_size=KERNEL_SIZE, stride=2, padding=math.floor(KERNEL_SIZE/2))\n",
        "        self.cnn_2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=KERNEL_SIZE, stride=2, padding=math.floor(KERNEL_SIZE/2))\n",
        "        self.cnn_3 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=KERNEL_SIZE, stride=2, padding=math.floor(KERNEL_SIZE/2))\n",
        "        self.dense_1 = nn.Linear(in_features=256, out_features=1)\n",
        "\n",
        "        self.dropout_1 = nn.Dropout(0.2)\n",
        "        self.dropout_2 = nn.Dropout(0.5)\n",
        "        self.dropout_3 = nn.Dropout(0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.hardtanh = nn.Hardtanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.batchnorm128 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm256 = nn.BatchNorm1d(256)\n",
        "                \n",
        "    def forward(self, inputs, times):\n",
        "        x = self.cnn_1(inputs)\n",
        "        x = self.batchnorm128(x)\n",
        "        x = self.hardtanh(x)\n",
        "        x = self.dropout_1(x)\n",
        "\n",
        "        x = self.cnn_2(x)\n",
        "        x = self.batchnorm256(x)\n",
        "        x = self.hardtanh(x)\n",
        "        x = self.dropout_2(x)\n",
        "\n",
        "        x = self.cnn_3(x)\n",
        "        x = self.batchnorm256(x)\n",
        "        x = self.hardtanh(x)\n",
        "        x = self.dropout_3(x)\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "        \n",
        "        x = self.dense_1(x)\n",
        "\n",
        "        sum_preds(times, x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEuBnLKMm5b4"
      },
      "source": [
        "model = binaryClassifier().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARaRI4ywz9o_"
      },
      "source": [
        "def sum_preds(time_batch, pred_batch, grad=True):\n",
        "  for idx in range(len(time_batch)):\n",
        "    timetable = time_batch[idx]\n",
        "    for span in timetable:\n",
        "      if span[1] != 0. and span[0] != span[1]:\n",
        "        start = int(span[0]) + 1\n",
        "        end = int(span[1]) + 1\n",
        "        pred_batch[idx][start:end] = sum(pred_batch[idx][start:end])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUxppNOlWrm8"
      },
      "source": [
        "def sum_labels(time_batch, label_batch, grad=False):\n",
        "  for idx in range(len(time_batch)):\n",
        "    timetable = time_batch[idx]\n",
        "    for span in timetable:\n",
        "      if span[1] != 0. and span[0] != span[1]:\n",
        "        start = int(span[0]) + 1\n",
        "        end = int(span[1]) + 1\n",
        "        mean_val = torch.mean(label_batch[idx][start:end])\n",
        "        if mean_val > 0.5:\n",
        "          label_batch[idx][start:end] = 1.\n",
        "        else:\n",
        "          label_batch[idx][start:end] = 0."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7D02tEew9Bc"
      },
      "source": [
        "## Train ConvNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-KDZFpJt9pf"
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([8])).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBrtEkevw5nG"
      },
      "source": [
        "model.train()\n",
        "\n",
        "for e in range(1, EPOCHS + 1):    \n",
        "  \n",
        "  e_loss = 0\n",
        "  \n",
        "  for batch in train_loader:\n",
        "      feature_batch = batch[\"features\"]\n",
        "      label_batch = batch[\"labels\"]\n",
        "      time_batch = batch[\"times\"]\n",
        "\n",
        "      feature_batch, label_batch, time_batch = feature_batch.to(device), label_batch.to(device), time_batch.to(device)\n",
        "\n",
        "      time_batch = time_batch.clone().detach().requires_grad_(True)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      pred_labels = model(feature_batch, time_batch)\n",
        "      sum_labels(time_batch, label_batch, grad=False)\n",
        "\n",
        "      loss = loss_func(pred_labels, label_batch)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      e_loss += loss.item()\n",
        "  \n",
        "  act_sig = nn.Sigmoid()\n",
        "  preds = act_sig(pred_labels).squeeze(1).cpu().detach().numpy().flatten()\n",
        "  preds_bin = np.where(preds > 0.5, 1, 0)\n",
        "  labels = np.array(label_batch.squeeze(1).cpu().detach().numpy(), dtype=int).flatten()\n",
        "  acc = accuracy_score(labels, preds_bin)\n",
        "  print(classification_report(labels, preds_bin))\n",
        "\n",
        "  print(f'Epoch {e+0:03}: | Loss: {e_loss/len(train_loader):.5f} | Accuracy: {acc:.5f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP9ZD1G5T2Zp"
      },
      "source": [
        "## Evaluate ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_PZdA5D2gL1",
        "outputId": "40470e53-b472-4b1a-de04-1c98feea3a83"
      },
      "source": [
        "val_data = DatasetWithTimings(val_features, val_labels, val_times, val_words, val_words_labels, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels input shape: torch.Size([873, 173, 1])\n",
            "Features input shape: torch.Size([873, 7, 1378])\n",
            "Timestamps input shape: torch.Size([873, 38, 2])\n",
            "Word features input shape: torch.Size([873, 38, 23])\n",
            "Word labels input shape: torch.Size([873, 38, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "UMY8qfDasOUr",
        "outputId": "ba672849-1609-4a12-b9f3-875962b3ac77"
      },
      "source": [
        "model1.eval()\n",
        "\n",
        "val_features = val_data.features_input.to(device)\n",
        "val_times = val_data.times_input.to(device)\n",
        "val_labels = val_data.labels_input.to(device)\n",
        "\n",
        "val_preds = model1(val_features, val_times)\n",
        "sum_labels(val_times, val_labels, grad=False)\n",
        "\n",
        "act_sig = nn.Sigmoid()\n",
        "val_preds = act_sig(val_preds).squeeze(1).cpu().detach().numpy().flatten()\n",
        "val_preds_bin = np.where(val_preds > 0.5, 1, 0)\n",
        "val_labels = np.array(val_labels.squeeze(1).cpu().detach().numpy(), dtype=int).flatten()\n",
        "print(classification_report(val_labels,val_preds_bin))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-63ebc6e5da6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHncIfJqiUuE"
      },
      "source": [
        "def eval_cnns(model, val_data):\n",
        "  model.eval()\n",
        "\n",
        "  val_features = val_data.features_input.to(device)\n",
        "  val_times = val_data.times_input.to(device)\n",
        "  val_words_labels = val_data.words_labels_input.to(device)\n",
        "\n",
        "  val_preds = model1(val_features, val_times)\n",
        "\n",
        "  utts = val_words_labels.shape[0]\n",
        "  words = val_words_labels.shape[1]\n",
        "\n",
        "  word_sums = torch.zeros(utts, words)\n",
        "\n",
        "  for idx in range(len(val_times)):\n",
        "    timetable = val_times[idx]\n",
        "    for jdx in range(len(timetable)):\n",
        "      span = timetable[jdx]\n",
        "      if span[1] != 0. and span[0] != span[1]:\n",
        "        start = int(span[0]) + 1\n",
        "        end = int(span[1]) + 1\n",
        "        word_sums[idx, jdx] = sum(val_preds[idx][start:end])\n",
        "\n",
        "  act_sig = nn.Sigmoid()\n",
        "  val_preds = act_sig(word_sums).cpu().detach().numpy().flatten()\n",
        "  val_preds_bin = np.where(val_preds > 0.5, 1, 0)\n",
        "  val_labels = np.array(val_words_labels.squeeze(1).cpu().detach().numpy(), dtype=int).flatten()\n",
        "  \n",
        "  with open(\"eval/cnn_model.report\", \"w\") as reportfile:\n",
        "    reportfile.write(classification_report(val_labels, val_preds_bin, digits=4))\n",
        "\n",
        "  prec, rec, _ = precision_recall_curve(val_labels, val_preds)\n",
        "  prec_rec_graph = PrecisionRecallDisplay(prec, rec, average_precision=0.5, estimator_name=\"CNN\").plot()\n",
        "  plt.savefig(\"eval/cnn_model_prec_rec_graph.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "NUMjpVAxwumu",
        "outputId": "e97f2c73-1230-4d8d-d1c3-a366a36de6e5"
      },
      "source": [
        "eval_cnns(model1, val_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bojp-FLoT_K4"
      },
      "source": [
        "## Load previous models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ekSNIEw2VEo"
      },
      "source": [
        "model1 = torch.load(\"model_store/frame_word_level/3cnn_30eps_94-157.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_WiG6-qUCAL"
      },
      "source": [
        "## Define LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3fQOzBK2j3r"
      },
      "source": [
        "FEATURES_LSTM = train_data.words_input.shape[2] + 1 \n",
        "EPOCHS_LSTM = 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzTkVWq86uKD"
      },
      "source": [
        "def prepare_input(word_features, preds, times, grad=True):\n",
        "  utts = word_features.shape[0]\n",
        "  words = word_features.shape[1]\n",
        "  feats = word_features.shape[2]\n",
        "  total_input = torch.zeros(utts, words, (feats + 1))\n",
        "  total_input[:, :, :-1] = word_features\n",
        "\n",
        "  for idx in range(len(times)):\n",
        "    timetable = times[idx]\n",
        "    for jdx in range(len(timetable)):\n",
        "      span = timetable[jdx]\n",
        "      if span[1] != 0. and span[0] != span[1]:\n",
        "        start = int(span[0]) + 1\n",
        "        end = int(span[1]) + 1\n",
        "        total_input[idx, jdx, -1] = sum(preds[idx][start:end])\n",
        "\n",
        "  total_input = total_input.clone().to(device).requires_grad_(grad)\n",
        "  return total_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a440CXmV0bUE"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(input_size=FEATURES_LSTM, hidden_size=128, num_layers=2,batch_first=True, bidirectional=True, dropout=0.2)\n",
        "        self.dense_1 = nn.Linear(in_features=256, out_features=1)\n",
        "\n",
        "        self.dropout_1 = nn.Dropout(0.5)\n",
        "        self.relu = nn.ReLU()\n",
        "                \n",
        "    def forward(self, inputs):\n",
        "        x, discard = self.lstm_1(inputs)\n",
        "        x, lengths = pad_packed_sequence(x, batch_first=True, total_length=40)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.dense_1(x)\n",
        "\n",
        "        return x, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M59fRlCZ220D"
      },
      "source": [
        "model2 = LSTMClassifier().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUvgUeXE4GxC"
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer = optim.Adam(model2.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh16Me1jQZlI"
      },
      "source": [
        "def get_seq_len(arr, idx):\n",
        "  if isinstance(idx, torch.Tensor):\n",
        "    seq_lens = torch.tensor([torch.tensor(len(arr[i]), dtype=torch.int64) for i in idx], dtype=torch.int64)\n",
        "  else:\n",
        "    seq_lens = torch.tensor([len(arr[idx])], dtype=torch.int64)\n",
        "  return seq_lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1m2Aq0LUGmN"
      },
      "source": [
        "## Train LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlBZ4BrpjPuu"
      },
      "source": [
        "def collect_metrics(m2_preds, batch_lengths, word_labels, indices):\n",
        "  act_sig = nn.Sigmoid()\n",
        "  preds = np.concatenate([act_sig(m2_preds[i, :batch_lengths[i], :]).cpu().detach().numpy() for i in range(len(m2_preds))]).flatten()\n",
        "  preds_bin = np.where(preds > 0.5, 1, 0)\n",
        "  labels = np.array(np.concatenate(word_labels[indices.cpu()]).flatten(), dtype=int)\n",
        "  return preds_bin, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTJcPFNX69bT"
      },
      "source": [
        "model_num = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP1eE_oC32Ph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cb916b-b20d-46f6-d29c-1468b10ef8e2"
      },
      "source": [
        "model2.train()\n",
        "max_e_f1 = 0\n",
        "\n",
        "for e in range(1, EPOCHS + 1):\n",
        "\n",
        "  e_loss = e_f1 = 0\n",
        "  e_labels = e_preds_bin = np.array([])\n",
        "\n",
        "  for batch in train_loader:\n",
        "      frame_feature_batch = batch[\"features\"].to(device)\n",
        "      frame_label_batch = batch[\"labels\"].to(device)\n",
        "      frame_time_batch = batch[\"times\"].to(device)\n",
        "\n",
        "      word_feature_batch = batch[\"words\"].to(device)\n",
        "      word_label_batch = batch[\"words_labels\"].to(device)\n",
        "\n",
        "      indices = batch[\"indices\"].to(device)\n",
        "\n",
        "      frame_time_batch = frame_time_batch.clone().detach().requires_grad_(True)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      m1_preds = model1(frame_feature_batch, frame_time_batch)\n",
        "      m2_input = prepare_input(word_feature_batch, m1_preds, frame_time_batch)\n",
        "\n",
        "      \n",
        "      m2_input_packed = pack_padded_sequence(m2_input, get_seq_len(train_words, indices), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "      m2_preds, batch_lengths = model2(m2_input_packed)\n",
        "\n",
        "      loss = loss_func(m2_preds, word_label_batch)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      e_loss += loss.item()\n",
        "\n",
        "      preds_bin, labels = collect_metrics(m2_preds, batch_lengths, train_words_labels, indices)\n",
        "      e_labels = np.concatenate([e_labels, labels])\n",
        "      e_preds_bin = np.concatenate([e_preds_bin, preds_bin])\n",
        "\n",
        "  print(classification_report(e_labels, e_preds_bin, digits=4))\n",
        "  results = classification_report(e_labels, e_preds_bin, output_dict=True)\n",
        "    \n",
        "  e_f1 = results[\"1.0\"][\"f1-score\"]\n",
        "\n",
        "  print(f'Epoch {e+0:03}: | Loss: {e_loss/len(train_loader):.5f}')\n",
        "\n",
        "  if e_f1 > max_e_f1:\n",
        "    for file in glob(f\"model_store/frame_word_level/model-{model_num}*\"):\n",
        "      os.remove(file)\n",
        "    \n",
        "    torch.save(model2, f\"model_store/frame_word_level/model-{model_num}_epoch-{e}_f1-{e_f1:.3f}.pt\")\n",
        "    max_e_f1 = e_f1\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.6875    0.4732    0.5605     13765\n",
            "         1.0     0.6128    0.7950    0.6921     14437\n",
            "\n",
            "    accuracy                         0.6379     28202\n",
            "   macro avg     0.6502    0.6341    0.6263     28202\n",
            "weighted avg     0.6493    0.6379    0.6279     28202\n",
            "\n",
            "Epoch 001: | Loss: 0.69132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7167    0.8224    0.7659     13765\n",
            "         1.0     0.8030    0.6900    0.7422     14437\n",
            "\n",
            "    accuracy                         0.7546     28202\n",
            "   macro avg     0.7598    0.7562    0.7541     28202\n",
            "weighted avg     0.7608    0.7546    0.7538     28202\n",
            "\n",
            "Epoch 002: | Loss: 0.66885\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7635    0.8322    0.7963     13765\n",
            "         1.0     0.8250    0.7542    0.7880     14437\n",
            "\n",
            "    accuracy                         0.7922     28202\n",
            "   macro avg     0.7942    0.7932    0.7922     28202\n",
            "weighted avg     0.7950    0.7922    0.7921     28202\n",
            "\n",
            "Epoch 003: | Loss: 0.64722\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7787    0.8182    0.7979     13765\n",
            "         1.0     0.8178    0.7783    0.7976     14437\n",
            "\n",
            "    accuracy                         0.7977     28202\n",
            "   macro avg     0.7982    0.7982    0.7977     28202\n",
            "weighted avg     0.7987    0.7977    0.7977     28202\n",
            "\n",
            "Epoch 004: | Loss: 0.64180\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7899    0.8178    0.8036     13765\n",
            "         1.0     0.8202    0.7926    0.8062     14437\n",
            "\n",
            "    accuracy                         0.8049     28202\n",
            "   macro avg     0.8051    0.8052    0.8049     28202\n",
            "weighted avg     0.8054    0.8049    0.8049     28202\n",
            "\n",
            "Epoch 005: | Loss: 0.63587\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.7965    0.8123    0.8043     13765\n",
            "         1.0     0.8176    0.8022    0.8098     14437\n",
            "\n",
            "    accuracy                         0.8071     28202\n",
            "   macro avg     0.8071    0.8072    0.8071     28202\n",
            "weighted avg     0.8073    0.8071    0.8071     28202\n",
            "\n",
            "Epoch 006: | Loss: 0.63157\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8055    0.8101    0.8078     13765\n",
            "         1.0     0.8179    0.8135    0.8157     14437\n",
            "\n",
            "    accuracy                         0.8118     28202\n",
            "   macro avg     0.8117    0.8118    0.8117     28202\n",
            "weighted avg     0.8119    0.8118    0.8118     28202\n",
            "\n",
            "Epoch 007: | Loss: 0.62660\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8124    0.8095    0.8110     13765\n",
            "         1.0     0.8190    0.8218    0.8204     14437\n",
            "\n",
            "    accuracy                         0.8158     28202\n",
            "   macro avg     0.8157    0.8156    0.8157     28202\n",
            "weighted avg     0.8158    0.8158    0.8158     28202\n",
            "\n",
            "Epoch 008: | Loss: 0.62175\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8198    0.8145    0.8171     13765\n",
            "         1.0     0.8242    0.8293    0.8267     14437\n",
            "\n",
            "    accuracy                         0.8220     28202\n",
            "   macro avg     0.8220    0.8219    0.8219     28202\n",
            "weighted avg     0.8220    0.8220    0.8220     28202\n",
            "\n",
            "Epoch 009: | Loss: 0.61729\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8279    0.8198    0.8238     13765\n",
            "         1.0     0.8297    0.8375    0.8336     14437\n",
            "\n",
            "    accuracy                         0.8288     28202\n",
            "   macro avg     0.8288    0.8286    0.8287     28202\n",
            "weighted avg     0.8288    0.8288    0.8288     28202\n",
            "\n",
            "Epoch 010: | Loss: 0.61216\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8306    0.8226    0.8266     13765\n",
            "         1.0     0.8324    0.8400    0.8362     14437\n",
            "\n",
            "    accuracy                         0.8315     28202\n",
            "   macro avg     0.8315    0.8313    0.8314     28202\n",
            "weighted avg     0.8315    0.8315    0.8315     28202\n",
            "\n",
            "Epoch 011: | Loss: 0.60775\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8345    0.8246    0.8295     13765\n",
            "         1.0     0.8346    0.8441    0.8393     14437\n",
            "\n",
            "    accuracy                         0.8346     28202\n",
            "   macro avg     0.8345    0.8343    0.8344     28202\n",
            "weighted avg     0.8346    0.8346    0.8345     28202\n",
            "\n",
            "Epoch 012: | Loss: 0.60386\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8391    0.8292    0.8341     13765\n",
            "         1.0     0.8390    0.8484    0.8436     14437\n",
            "\n",
            "    accuracy                         0.8390     28202\n",
            "   macro avg     0.8390    0.8388    0.8389     28202\n",
            "weighted avg     0.8390    0.8390    0.8390     28202\n",
            "\n",
            "Epoch 013: | Loss: 0.59935\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8457    0.8336    0.8396     13765\n",
            "         1.0     0.8435    0.8550    0.8492     14437\n",
            "\n",
            "    accuracy                         0.8446     28202\n",
            "   macro avg     0.8446    0.8443    0.8444     28202\n",
            "weighted avg     0.8446    0.8446    0.8445     28202\n",
            "\n",
            "Epoch 014: | Loss: 0.59495\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8466    0.8328    0.8396     13765\n",
            "         1.0     0.8430    0.8561    0.8495     14437\n",
            "\n",
            "    accuracy                         0.8447     28202\n",
            "   macro avg     0.8448    0.8445    0.8446     28202\n",
            "weighted avg     0.8448    0.8447    0.8447     28202\n",
            "\n",
            "Epoch 015: | Loss: 0.59140\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8520    0.8397    0.8458     13765\n",
            "         1.0     0.8493    0.8609    0.8550     14437\n",
            "\n",
            "    accuracy                         0.8506     28202\n",
            "   macro avg     0.8506    0.8503    0.8504     28202\n",
            "weighted avg     0.8506    0.8506    0.8505     28202\n",
            "\n",
            "Epoch 016: | Loss: 0.58706\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8532    0.8393    0.8462     13765\n",
            "         1.0     0.8491    0.8624    0.8557     14437\n",
            "\n",
            "    accuracy                         0.8511     28202\n",
            "   macro avg     0.8512    0.8508    0.8510     28202\n",
            "weighted avg     0.8511    0.8511    0.8511     28202\n",
            "\n",
            "Epoch 017: | Loss: 0.58422\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8542    0.8424    0.8482     13765\n",
            "         1.0     0.8517    0.8629    0.8573     14437\n",
            "\n",
            "    accuracy                         0.8529     28202\n",
            "   macro avg     0.8529    0.8526    0.8527     28202\n",
            "weighted avg     0.8529    0.8529    0.8529     28202\n",
            "\n",
            "Epoch 018: | Loss: 0.58073\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8575    0.8453    0.8513     13765\n",
            "         1.0     0.8544    0.8660    0.8602     14437\n",
            "\n",
            "    accuracy                         0.8559     28202\n",
            "   macro avg     0.8560    0.8556    0.8558     28202\n",
            "weighted avg     0.8559    0.8559    0.8559     28202\n",
            "\n",
            "Epoch 019: | Loss: 0.57702\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8599    0.8475    0.8537     13765\n",
            "         1.0     0.8566    0.8683    0.8624     14437\n",
            "\n",
            "    accuracy                         0.8582     28202\n",
            "   macro avg     0.8582    0.8579    0.8580     28202\n",
            "weighted avg     0.8582    0.8582    0.8581     28202\n",
            "\n",
            "Epoch 020: | Loss: 0.57399\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8606    0.8490    0.8547     13765\n",
            "         1.0     0.8578    0.8689    0.8633     14437\n",
            "\n",
            "    accuracy                         0.8592     28202\n",
            "   macro avg     0.8592    0.8589    0.8590     28202\n",
            "weighted avg     0.8592    0.8592    0.8591     28202\n",
            "\n",
            "Epoch 021: | Loss: 0.57089\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8600    0.8501    0.8550     13765\n",
            "         1.0     0.8587    0.8680    0.8633     14437\n",
            "\n",
            "    accuracy                         0.8593     28202\n",
            "   macro avg     0.8593    0.8591    0.8592     28202\n",
            "weighted avg     0.8593    0.8593    0.8593     28202\n",
            "\n",
            "Epoch 022: | Loss: 0.56812\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8609    0.8512    0.8560     13765\n",
            "         1.0     0.8596    0.8689    0.8642     14437\n",
            "\n",
            "    accuracy                         0.8603     28202\n",
            "   macro avg     0.8603    0.8600    0.8601     28202\n",
            "weighted avg     0.8603    0.8603    0.8602     28202\n",
            "\n",
            "Epoch 023: | Loss: 0.56521\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8621    0.8527    0.8574     13765\n",
            "         1.0     0.8610    0.8700    0.8655     14437\n",
            "\n",
            "    accuracy                         0.8616     28202\n",
            "   macro avg     0.8616    0.8614    0.8615     28202\n",
            "weighted avg     0.8616    0.8616    0.8615     28202\n",
            "\n",
            "Epoch 024: | Loss: 0.56199\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8611    0.8551    0.8581     13765\n",
            "         1.0     0.8627    0.8685    0.8656     14437\n",
            "\n",
            "    accuracy                         0.8620     28202\n",
            "   macro avg     0.8619    0.8618    0.8619     28202\n",
            "weighted avg     0.8620    0.8620    0.8619     28202\n",
            "\n",
            "Epoch 025: | Loss: 0.55931\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8648    0.8534    0.8590     13765\n",
            "         1.0     0.8620    0.8728    0.8673     14437\n",
            "\n",
            "    accuracy                         0.8633     28202\n",
            "   macro avg     0.8634    0.8631    0.8632     28202\n",
            "weighted avg     0.8633    0.8633    0.8633     28202\n",
            "\n",
            "Epoch 026: | Loss: 0.55582\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8673    0.8554    0.8613     13765\n",
            "         1.0     0.8639    0.8753    0.8696     14437\n",
            "\n",
            "    accuracy                         0.8656     28202\n",
            "   macro avg     0.8656    0.8653    0.8655     28202\n",
            "weighted avg     0.8656    0.8656    0.8655     28202\n",
            "\n",
            "Epoch 027: | Loss: 0.55325\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8679    0.8542    0.8610     13765\n",
            "         1.0     0.8631    0.8761    0.8695     14437\n",
            "\n",
            "    accuracy                         0.8654     28202\n",
            "   macro avg     0.8655    0.8651    0.8653     28202\n",
            "weighted avg     0.8654    0.8654    0.8654     28202\n",
            "\n",
            "Epoch 028: | Loss: 0.55050\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8685    0.8556    0.8620     13765\n",
            "         1.0     0.8643    0.8764    0.8703     14437\n",
            "\n",
            "    accuracy                         0.8663     28202\n",
            "   macro avg     0.8664    0.8660    0.8662     28202\n",
            "weighted avg     0.8663    0.8663    0.8663     28202\n",
            "\n",
            "Epoch 029: | Loss: 0.54796\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8710    0.8567    0.8638     13765\n",
            "         1.0     0.8655    0.8790    0.8722     14437\n",
            "\n",
            "    accuracy                         0.8681     28202\n",
            "   macro avg     0.8682    0.8679    0.8680     28202\n",
            "weighted avg     0.8682    0.8681    0.8681     28202\n",
            "\n",
            "Epoch 030: | Loss: 0.54491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCmhJHM7tMBk"
      },
      "source": [
        "## Evaluate LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x14HjaDFtT7P",
        "outputId": "1852f4fb-449d-462f-80ab-f2785b487689"
      },
      "source": [
        "val_data = DatasetWithTimings(val_features, val_labels, val_times, val_words, val_words_labels, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels input shape: torch.Size([873, 173, 1])\n",
            "Features input shape: torch.Size([873, 7, 1378])\n",
            "Timestamps input shape: torch.Size([873, 38, 2])\n",
            "Word features input shape: torch.Size([873, 38, 23])\n",
            "Word labels input shape: torch.Size([873, 38, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8GR2S4ew4qk"
      },
      "source": [
        "model_file = \"model-1_epoch-30_f1-0.872.pt\"\n",
        "eval_model = torch.load(f\"model_store/frame_word_level/{model_file}\")\n",
        "eval_model.eval()\n",
        "\n",
        "val_features = val_data.features_input.to(device)\n",
        "val_times = val_data.times_input.to(device)\n",
        "val_labels = val_data.labels_input.to(device)\n",
        "val_word_features = val_data.words_input.to(device)\n",
        "val_word_labels = val_data.words_labels_input.to(device)\n",
        "val_indices = torch.tensor([x for x in range(len(val_data.words))])\n",
        "\n",
        "val_m1_preds = model1(val_features, val_times)\n",
        "val_m2_input = prepare_input(val_word_features, val_m1_preds, val_times)\n",
        "val_m2_input_packed = pack_padded_sequence(val_m2_input, get_seq_len(val_data.words, val_indices), batch_first=True, enforce_sorted=False)\n",
        "val_m2_preds, val_batch_lengths = eval_model(val_m2_input_packed)\n",
        "\n",
        "val_preds_bin, val_labels = collect_metrics(val_m2_preds, val_batch_lengths, val_data.words_labels, val_indices)\n",
        "with open(f\"eval/frame_word_level/{model_file}.txt\", \"w\") as reportfile:\n",
        "  reportfile.write(classification_report(val_labels, val_preds_bin, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lRqfB15bFvD"
      },
      "source": [
        "torch.save(model2, \"1lstm-60eps.model\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}