{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "pytorch-gpu.1-4.m49",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": "2000"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "359.933px",
        "left": "1653.71px",
        "right": "20px",
        "top": "148.966px",
        "width": "453.267px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "name": "lstm_nucleus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFLWIeUDuRCz"
      },
      "source": [
        "# Nucleus-level LSTM Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv_maCh583MH"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H650bleQ83MJ"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDR66Ej583MP"
      },
      "source": [
        "## Set working directory and load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqQJpypKmQuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78498ad-5ccf-4e79-995b-531c8c735fa4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4RhnIl783MQ"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OtK1rBi83MV"
      },
      "source": [
        "data_features = np.load(\"data/nucleus_level/nucleus_features.npy\", allow_pickle=True)\n",
        "data_labels = np.load(\"data/nucleus_level/nucleus_labels.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zPDCHL383MZ"
      },
      "source": [
        "## Split into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DBpcnqAVZ6X"
      },
      "source": [
        "train_features, val_features, train_labels, val_labels = train_test_split(data_features, data_labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QMVful483Me"
      },
      "source": [
        "def to_tensor(data_list):\n",
        "    return [torch.FloatTensor(data) for data in data_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dipxqHyc83Mj"
      },
      "source": [
        "train_features_input = pad_sequence(to_tensor(train_features), batch_first=True)\n",
        "val_features_input = pad_sequence(to_tensor(val_features), batch_first=True)\n",
        "train_labels_input = pad_sequence(to_tensor(train_labels), batch_first=True)\n",
        "val_labels_input = pad_sequence(to_tensor(val_labels), batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxKdaY4JGI-v",
        "outputId": "5713d853-2aab-4d3f-8393-a26f7d76a5e1"
      },
      "source": [
        "print(train_features_input.shape)\n",
        "print(train_labels_input.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([44, 2195, 26])\n",
            "torch.Size([44, 2195])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgiza7AH83Mw"
      },
      "source": [
        "## Run sets as PyTorch Datasets through PyTorch DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u23zbhGU83Mw"
      },
      "source": [
        "### Sets to PyTorch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_CW7j0q83Mx"
      },
      "source": [
        "class trainData(Dataset):\n",
        "    \n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index], self.labels[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjVa_fef83M1"
      },
      "source": [
        "train_data = trainData(torch.FloatTensor(train_features_input), torch.FloatTensor(train_labels_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gpDE5zb83NC"
      },
      "source": [
        "## Set basic training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC3EAzQzFTpC"
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 11\n",
        "LEARNING_RATE = 1e-03\n",
        "\n",
        "LENGTH = train_features_input.shape[0]\n",
        "NUM_FEATURES = train_features_input.shape[2]\n",
        "SEQUENCE = train_features_input.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq03ChjC83NJ"
      },
      "source": [
        "### Initialize DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D9zxXnU83NK"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOaKIN9k83NS"
      },
      "source": [
        "## Ready GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kiqpu3q83NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4f3785-3d2b-49f2-b656-f4a7b43b8a4b"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmsHeQvW83NW"
      },
      "source": [
        "## Define neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJEVOvB-83NW"
      },
      "source": [
        "class binaryClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(binaryClassifier, self).__init__() # initialize parent class\n",
        "\n",
        "        self.lstm_1 = nn.LSTM(input_size=NUM_FEATURES, hidden_size=128, num_layers=2, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.dense_1 = nn.Linear(in_features=256, out_features=32)\n",
        "        self.dense_2 = nn.Linear(in_features=32, out_features=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout_1 = nn.Dropout(0.4)\n",
        "        self.dropout_2 = nn.Dropout(0.4)\n",
        "                \n",
        "    def forward(self, inputs):\n",
        "        lstm_out, (h, c) = self.lstm_1(inputs)\n",
        "        x, lengths = pad_packed_sequence(lstm_out, batch_first=True, total_length=2195)\n",
        "\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.dense_2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI46lYQ383Ne"
      },
      "source": [
        "## Initialize model and move to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucf33TYX83Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de5d34a-ba4b-4d2c-ddb0-e41f43087a8f"
      },
      "source": [
        "model = binaryClassifier()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "binaryClassifier(\n",
              "  (lstm_1): LSTM(26, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (dense_1): Linear(in_features=256, out_features=32, bias=True)\n",
              "  (dense_2): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout_1): Dropout(p=0.4, inplace=False)\n",
              "  (dropout_2): Dropout(p=0.4, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-mfCMEU83Nn"
      },
      "source": [
        "## Define loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwMwpZr383No"
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([3])).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BEZYQinvC3e"
      },
      "source": [
        "## Define function to determine real sequence length and define metrics function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YRZDZTUvLCl"
      },
      "source": [
        "def get_seq_len(seq):\n",
        "  with torch.no_grad():\n",
        "    lens = []\n",
        "    for e in seq:\n",
        "      e_no_0 = len(e[torch.where(~torch.all(torch.isclose(e, torch.cuda.FloatTensor([0])), axis=1))])\n",
        "      lens.append(e_no_0)\n",
        "    return lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMu-IsXYd6JJ"
      },
      "source": [
        "def collect_metrics(preds, lengths, labels):\n",
        "  act_sig = nn.Sigmoid()\n",
        "  preds = np.concatenate([act_sig(preds[i, :lengths[i], :]).cpu().detach().numpy() for i in range(len(preds))]).flatten()\n",
        "  preds_bin = np.where(preds > 0.5, 1, 0)\n",
        "  labels = np.array(np.concatenate([labels[i, :lengths[i]].cpu().detach().numpy() for i in range(len(labels))]), dtype=int).flatten()\n",
        "  return preds_bin, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpQoEJmFIOxA"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KsyBijLcna1"
      },
      "source": [
        "model_num = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ItBgD683N5"
      },
      "source": [
        "model.train()\n",
        "max_e_f1 = 0\n",
        "\n",
        "for e in range(1, EPOCHS + 1):\n",
        "    e_loss = e_f1 = 0\n",
        "    e_preds_bin = e_labels = np.array([])\n",
        "    \n",
        "    for feature_batch, label_batch in train_loader:\n",
        "        \n",
        "        torch.autograd.set_detect_anomaly(True)\n",
        "        feature_batch, label_batch = feature_batch.to(device), label_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_lengths = get_seq_len(feature_batch)\n",
        "\n",
        "        input_features = pack_padded_sequence(feature_batch, input_lengths, batch_first=True, enforce_sorted=False)\n",
        "        \n",
        "        pred_labels = model(input_features)\n",
        "\n",
        "        loss = loss_func(pred_labels, label_batch.unsqueeze(2))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        e_loss += loss.item()\n",
        "\n",
        "        preds_bin, labels = collect_metrics(pred_labels, input_lengths, label_batch)\n",
        "        e_labels = np.concatenate([e_labels, labels])\n",
        "        e_preds_bin = np.concatenate([e_preds_bin, preds_bin])\n",
        "\n",
        "    print(classification_report(e_labels, e_preds_bin, digits=4))\n",
        "    results = classification_report(e_labels, e_preds_bin, output_dict=True)\n",
        "\n",
        "    e_f1 = results[\"1.0\"][\"f1-score\"]\n",
        "\n",
        "    print(f'Epoch {e+0:03}: | Loss: {e_loss/len(train_loader):.5f}')\n",
        "    if e_f1 > max_e_f1:\n",
        "      for file in glob(f\"model_store/nucleus_level/model-{model_num}*\"):\n",
        "        os.remove(file)\n",
        "      \n",
        "      torch.save(model, f\"model_store/nucleus_level/model-{model_num}_epoch-{e}_f1-{e_f1:.3f}.pt\")\n",
        "      max_e_f1 = e_f1\n",
        "    else:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4U4-VsEIz14"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9j8AomqIl52"
      },
      "source": [
        "model_file = \"model-10_epoch-49_f1-0.603.pt\"\n",
        "eval_model = torch.load(f\"model_store/nucleus_level/{model_file}\").eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J4BPbDSlJjr"
      },
      "source": [
        "val_data = trainData(torch.FloatTensor(val_features_input), torch.FloatTensor(val_labels_input))\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=11, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrR9PNYGj1r2"
      },
      "source": [
        "for feature_batch, label_batch in val_loader:\n",
        "  feature_batch = feature_batch.to(device)\n",
        "  input_lengths = get_seq_len(feature_batch)\n",
        "  input_features = pack_padded_sequence(feature_batch, input_lengths, batch_first=True, enforce_sorted=False)\n",
        "  \n",
        "  \n",
        "  y_pred = eval_model(input_features)\n",
        "  y_true, y_pred_bin = collect_metrics(y_pred, input_lengths, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiBZqy_oekVH",
        "outputId": "74903792-8943-4293-ac87-2ee741206b20"
      },
      "source": [
        "report = classification_report(y_true, y_pred_bin, digits=4)\n",
        "print(report)\n",
        "with open(f\"eval/nucleus_level/{model_file}.txt\", \"w\") as reportfile:\n",
        "  reportfile.write(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6907    0.9189    0.7886      7076\n",
            "           1     0.8194    0.4722    0.5991      5517\n",
            "\n",
            "    accuracy                         0.7232     12593\n",
            "   macro avg     0.7551    0.6955    0.6939     12593\n",
            "weighted avg     0.7471    0.7232    0.7056     12593\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}